---
title: "Final Project" 
author: "Philip Saroka"
output: html_notebook
---
```{r}
#install.packages(c("cowplot", "googleway", "ggplot2", "ggrepel", 
#"ggspatial", "libwgeom", "sf", "rnaturalearth", "rnaturalearthdata", 
#"rworldxtra","ggmap","digest","glue","cowplot"))
```
```{r}
#install.packages()
```
```{r warning=TRUE}
# clean up workspace environment
rm(list = ls())

# all packages used for the assignment
library(mosaicData)
library(mosaic)
library(DataComputing)
library(tidyverse)
library(forcats)
library(lubridate)
library(readxl)
library(ggplot2)
theme_set(theme_bw())
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(sp)
library(rworldmap)
library(rworldxtra)
library(leaflet)
library(data.table)
library(rgdal)
library(KernSmooth)
library(raster)
```

Tre Butler, Phil Saroka, Jessica Schick
#Research Question:

How have outside factors like weather and time affected the crime rates of Boston?

#Data Sources:

##Where did you find them? (I don’t think we should just say Google)
- Boston crime rates data - https://www.kaggle.com/ankkur13/boston-crime-data
- Boston weather data - Global Historical Climatology Network

##Who collected/maintains them?
- Boston crime rates data - AnkurJain formed the dataset on Kaggle, but the information to create the dataset comes from the Boston Police Department
- Boston weather data - The NOAA gathers it’s data from many sources including the World Meteorological Organization

##When & Why were they originally collected? 

A) Boston crime rates data - The dataset started in 2015 and was originally collected to find trends in crime statistics.
B) Boston weather data - The NOAA has kept weather statistics for many places for the past 30 years. They are collected for convenience to those who need to study trends in the weather.

##What does a case represent in each data source, and how many total cases are available?
Boston crime rates data - each case represent an Incident Number and there are a total of 260,760 cases available to use
Boston weather data - each case represent the Date of the Year and there are a total of 1,221 cases available to use

##What are some of the variables that you plan to use?
Boston crime rates data - Incident Number, Occurred on Date, Year, Month, Day of the Week, Hour, UCR Part, Street, Latitude, Longitude, Location, Offense Code
Boston weather data - Name, Latitude, Longitude, Date, Precipitation, Snow, Temperature Average
Plots, Summary Stats, and Observations

##Create some informative plots and summary statistics 

##Describe preliminary observations and intuition about the research question

##TWO Data Sources (at least)
Primary data:  Boston Crime Data 
Other data sources: Boston Weather Data









```{r message=FALSE, warning=FALSE}
#creating the datasets
boston_crime_statistics <- read_excel("crime.xlsx")
weather_data <- read_csv("weather data.csv")
weather_data <- weather_data%>%
  select(NAME,LATITUDE,LONGITUDE,DATE,PRCP, TAVG,SNOW)
```

```{r}
boston_crime_statistics
```
```{r}
weather_data
```

```{r}
date_of_incident <- boston_crime_statistics%>%
  select(INCIDENT_NUMBER,OCCURRED_ON_DATE,YEAR,MONTH,DAY_OF_WEEK,HOUR)%>%
  arrange(OCCURRED_ON_DATE)
location_of_incident <- boston_crime_statistics%>%
  select(INCIDENT_NUMBER,OCCURRED_ON_DATE,UCR_PART,STREET,Lat,Long, Location)%>%
  arrange(OCCURRED_ON_DATE)
```

```{r}
date_of_incident
```
```{r}
location_of_incident
```

```{r}
#date ranges
first_date<-boston_crime_statistics%>%
  select(OCCURRED_ON_DATE,YEAR,MONTH,DAY_OF_WEEK,HOUR)%>%
  arrange(OCCURRED_ON_DATE)%>%
  head(1)

last_date<-boston_crime_statistics%>%
  select(OCCURRED_ON_DATE,YEAR,MONTH,DAY_OF_WEEK,HOUR)%>%
  arrange(OCCURRED_ON_DATE)%>%
  tail(1)
first_date
last_date
```

```{r}
#number of day over which the data is recorded
last_date[1, "OCCURRED_ON_DATE"]-first_date[1, "OCCURRED_ON_DATE"]
```
```{r}
small_data <- boston_crime_statistics%>%
  group_by(OFFENSE_CODE)%>%
  summarise(total = n())
```
```{r}
ggplot(data=small_data,aes(x=OFFENSE_CODE,y=total))+geom_point()
```
In this graph we can see that there are clusters of offense codes that are more common that others

```{r}

world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)

ggplot(data = world) +
    geom_sf() +
    coord_sf(xlim = c(40, 42), ylim = c(70, 72), expand = FALSE) +
    geom_density_2d(data=location_of_incident%>%head(10),aes(x=Long,y=Lat))
data(world.cities)


```

```{r}
location_of_incident
```
```{r}
lang<-location_of_incident%>%filter(Lat>40)%>%filter(Long<(-70))
lang
```
```{r}
lat_avg=mean(lang$Lat,na.rm = T)
lng_avg=mean(lang$Long,na.rm = T)
lat_avg
lng_avg
```


```{r}
ggplot(data=lang%>%head(10000),aes(x=Long,y=Lat))+geom_density_2d()
```
```{r}
states <- map_data("state")
dim(states)
ca_df <- subset(states, region == "california")
counties <- map_data("county")
ca_county <- subset(counties, region == "california")
ca_base <- ggplot(data = ca_df, mapping = aes(x = long, y = lat, group = group)) + 
  coord_fixed(1.3) + 
  geom_polygon(color = "black", fill = "gray")
  ca_base + theme_nothing() + 
  geom_polygon(data = ca_county, fill = NA, color = "white") +
  geom_polygon(color = "black", fill = NA) + # get the state border back on top
  ggplot(data=lang%>%head(10000),aes(x=Lat,y=Long))+geom_density_2d()

```


```{r}
locationMap <-
  leaflet(lang%>%head(10)) %>%   # like ggplot()
  addTiles() %>%          # add the map
  addCircleMarkers(radius=2, color="red") %>%
  setView(lng_avg, lat_avg, zoom=12)
locationMap
```

```{r}
#inurl <- "https://data.cityofchicago.org/api/views/22s8-eq8h/rows.csv?accessType=DOWNLOAD"
#infile <- "mvthefts.csv"

## LOAD DATA
## Also, clean up variable names, and convert dates
#if(!file.exists(infile)){
#  download.file(url = inurl, destfile = infile)
#}
#dat <- data.table::fread(infile)

dlang<-lang%>%select(Long,Lat)
## Create kernel density output
kde <- bkde2D(dlang,
              bandwidth=c(.0045, .0068), gridsize = c(100,100))
# Create Raster from Kernel Density output
KernelDensityRaster <- raster(list(x=kde$x1 ,y=kde$x2 ,z = kde$fhat))

#create pal function for coloring the raster
palRaster <- colorNumeric("Spectral", domain = KernelDensityRaster@data@values)

## Leaflet map with raster
leaflet() %>% addTiles() %>% 
  addRasterImage(KernelDensityRaster, 
                 colors = palRaster, 
                 opacity = .8) %>%
  addLegend(pal = palRaster, 
            values = KernelDensityRaster@data@values, 
            title = "Kernel Density of Points")
```
```{r}
#set low density cells as NA so we can make them transparent with the colorNumeric function
 KernelDensityRaster@data@values[which(KernelDensityRaster@data@values < 1)] <- NA

#create pal function for coloring the raster
palRaster <- colorNumeric("Spectral", domain = KernelDensityRaster@data@values, na.color = "transparent")

## Redraw the map
leaflet() %>% addTiles() %>% 
  addRasterImage(KernelDensityRaster, 
                 colors = palRaster, 
                 opacity = .8) %>%
  addLegend(pal = palRaster, 
            values = KernelDensityRaster@data@values, 
            title = "Kernel Density of Points")

```

